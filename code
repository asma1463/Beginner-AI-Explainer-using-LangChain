from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain_core.prompts import PromptTemplate

# Load .env variables
load_dotenv()

# Create LLM (FREE model from Groq)
llm = ChatGroq(
    model="llama-3.1-8b-instant",
    temperature=0.7
)

# Prompt template
prompt = PromptTemplate(
    input_variables=["topic"],
    template="Explain {topic} in very simple words as if I am a beginner."
)

# User input
topic = input("Enter a topic: ")

# Format prompt
formatted_prompt = prompt.format(topic=topic)

# Get AI response
response = llm.invoke(formatted_prompt)

print("\nAI Response:\n")
print(response.content)
